# -*- coding: utf-8 -*-
"""languageprocessor_nltk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gWJ-zIVuTzpX1AKvmYwEqumgq5PaTAEo
"""

# clean text
def clean_string(text):
    text = ''.join([word for word in text if word not in string.punctuation])
    text = text.lower()
    text = ' '.join([word for word in text.split() if word not in stopwords])
    return text









# vectorizer
def vectorizer(cleaned_text):
    vectorizer = CountVectorizer().fit_transform(cleaned_text)
    vectors = vectorizer.toarray()
    return vectors

# cosine similarity
def csim(vectors):
    csim = cosine_similarity(vectors)
    return csim

# calculate cosine similarity
def cosine_sim_vectors(vec1, vec2):
    vec1 = vec1.reshape(1, -1)
    vec2 = vec2.reshape(1, -1)

    return cosine_similarity(vec1, vec2)[0][0]

import math
import re
from collections import Counter

WORD = re.compile(r"\w+")

def text_to_vector(text):
    words = WORD.findall(text)
    return Counter(words)


def get_cosine(vec1, vec2):
    intersection = set(vec1.keys()) & set(vec2.keys())
    numerator = sum([vec1[x] * vec2[x] for x in intersection])

    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])
    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])
    denominator = math.sqrt(sum1) * math.sqrt(sum2)

    if not denominator:
        return 0.0
    else:
        return float(numerator) / denominator

import nltk
nltk.download('stopwords')
stopwords = stopwords.words('english')

import json
import random
import string
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords

import nltk
nltk.download('punkt')

from nltk.text import sent_tokenize
def main():
    userinput = "when is exam 1?"
    cleaned_user = clean_string(userinput)
    best_cos = 0
    with open("test.txt") as f:
        line = f.readline()
        sentence = sent_tokenize(line)
        for i in range(0,len(sentence)):
          text = sentence[i]
          cleaned = clean_string(text)
          vector1 = text_to_vector(cleaned)
          vector2 = text_to_vector(cleaned_user)
          cosine = get_cosine(vector1, vector2)
          if cosine > best_cos: 
            best_cos = cosine
            best_sent  = text
    
        while line: 
          line = f.readline()
          sentence = sent_tokenize(line)
          for i in range(0,len(sentence)):
            text = sentence[i]
            cleaned = clean_string(text)
            vector1 = text_to_vector(cleaned)
            vector2 = text_to_vector(cleaned_user)
            cosine = get_cosine(vector1, vector2)
            if cosine > best_cos: 
              best_cos = cosine
              best_sent  = text
              print(best_sent)
     

    print(best_cos)
    print(best_sent)
main()